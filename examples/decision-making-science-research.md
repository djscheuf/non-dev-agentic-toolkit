---
title: "How to Make a Big Decision - Research Summary"
tags:
  - decision-making
  - cognitive-science
  - critical-thinking
  - premortem
  - scenario-planning
source: "https://www.nytimes.com/2018/09/01/opinion/sunday/how-make-big-decision.html"
author: "Steven Johnson"
dateCreated: 2018-09-01
---

# Research Summary: How to Make a Big Decision

*Source: [Steven Johnson, NYT Opinion](https://www.nytimes.com/2018/09/01/opinion/sunday/how-make-big-decision.html)*

## Core Thesis

Decades of multidisciplinary research has evolved beyond Darwin's simple pros-and-cons list, providing evidence-based tools for making complex decisions with long-term consequences. While no algorithm guarantees perfect choices, these techniques help you see situations from new perspectives and weigh options more sophisticatedly.

## Key Research Findings

**The Alternative Generation Problem**

Paul Nutt's organizational decision studies (1980s) revealed a striking pattern: only 15-29% of decision makers actively sought alternatives beyond initial options. Yet decisions involving multiple alternatives succeeded two-thirds of the time, while single-option "whether or not" decisions failed over 50% of the time.

**Key insight**: Transform "whether or not" questions into "which one" questions with multiple paths.

**Diversity Improves Decision Quality**

Samuel Sommers' mock jury research showed racially diverse groups:
- Considered more interpretations of evidence
- Remembered information more accurately  
- Engaged with more rigor and persistence
- Were more likely to reach correct conclusions
- Were paradoxically less confident (more open to being wrong)

Homogeneous groups settle on conclusions too quickly and don't question assumptions.

## Four Evidence-Based Techniques

| Technique | Purpose | How It Works |
|-----------|---------|--------------|
| **Generate Alternatives** | Expand option pool | Diversify decision-making group; actively seek new options beyond initial choices |
| **Scenario Planning** | Test robustness | Create three stories per alternative: things get better, worse, and weird |
| **Premortem Analysis** | Surface blind spots | Imagine the decision failed; work backward to identify causes (30% better at identifying risks) |
| **Value Model** | Systematic evaluation | Weight core values (0-1), grade each scenario (1-100), multiply and sum scores |

## The Value Model Framework

Darwin's approach updated for systematic evaluation:

1. **List core values** (e.g., freedom, companionship, having children, career growth)
2. **Weight each value** (0-1 scale based on importance to you)
3. **Grade each scenario** (1-100) on how well it addresses each value
4. **Calculate**: Multiply grade Ã— weight for each value, sum totals
5. **Compare**: Highest score indicates best alignment with your values

## The Premortem Advantage

Gary Klein's premortem technique leverages "prospective hindsight" - imagining failure has already occurred increases risk identification by 30%. By assuming failure and working backward, teams surface blind spots that forward-thinking planning misses. The technique provides psychological safety for raising concerns and combats hindsight bias.

## Why These Tools Work

The fundamental limitation of pros-and-cons lists: they merely transcribe existing understanding without generating fresh perspectives. As Thomas Schelling observed, "One thing a person cannot do, no matter how rigorous his analysis or heroic his imagination, is to draw up a list of things that would never occur to him."

Complex decisions require imaginative leaps to discover new paths and outcomes. These tools help you see each unique constellation of variables more clearly from multiple angles.

## Relevance to Decision Facilitation Workflow

This research directly supports several aspects of the decision facilitation workflow:

**Alternative Generation**: The workflow requires evaluating 2-3 options minimum (Phase 3), directly addressing Nutt's finding that single-option decisions fail over 50% of the time.

**Scenario Planning**: The trade-off evaluation phase asks for positives, negatives, and feasibility - a simplified form of scenario planning that tests each option's robustness.

**Premortem Analysis**: The feedback design phase (Phase 6) includes "failure conditions" - asking "at what point do we revisit or reverse this decision?" This builds in prospective hindsight.

**Value Model**: The boundary conditions phase (Phase 2) establishes what must be satisfied, similar to identifying core values. The trade-off evaluation then grades options against these criteria.

**Diversity**: While the workflow is for individual decision-makers, the context-gathering prompts encourage seeking diverse perspectives and challenging assumptions.

## Complementary Techniques

These research-backed techniques complement Drucker's Elements of Decision Making:

- **Drucker**: "Is this generic or exceptional?" 
- **Research**: Generate alternatives to avoid single-option trap

- **Drucker**: "What are the boundary conditions?"
- **Research**: Value model helps weight and evaluate against criteria

- **Drucker**: "Think through what's right before compromises"
- **Research**: Scenario planning tests each option's robustness

- **Drucker**: "Build in feedback to test against reality"
- **Research**: Premortem surfaces failure modes to monitor

## Related Reading

- Paul Nutt's organizational decision research (1984, later studies)
- Samuel Sommers' jury diversity studies  
- Katherine Phillips' management research on diverse groups (2008)
- Gary Klein's premortem technique
- Steven Johnson's book *Farsighted: How We Make the Decisions That Matter the Most*

## Application to Non-Technical Decisions

These techniques are particularly valuable for the strategic, operational, and tactical decisions the workflow targets:

**Strategic decisions** benefit from scenario planning (better/worse/weird futures) and premortem analysis (what could derail our strategy?).

**Operational decisions** benefit from alternative generation (don't accept the first solution) and value models (systematic evaluation against operational goals).

**Tactical decisions** benefit from rapid alternative generation and simplified scenario planning (what if this works? what if it doesn't?).

The research validates the workflow's emphasis on:
1. Generating multiple options (not "whether or not" but "which one")
2. Systematic evaluation against criteria (boundary conditions)
3. Prospective thinking about failure (feedback design)
4. Testing assumptions (Cynefin domain, generic vs exceptional)
